---
author: owent
categories:
  - Article
  - Blablabla
date: 2024-09-28 11:39:45
draft: true
id: 2405
tags: 
  - c++
  - cpp
  - cxx
  - shared_ptr
  - smart_ptr
  - strong_rc_ptr
title: 实现一个strong_rc_ptr(非线程安全版本的std::shared_ptr)
type: post
---

## 背景

我们的新项目有个比较复杂的全区全服交易行系统，其中搜索和推荐是高实时性全区服多维度排序的，并且要支持比较复杂的标签交集查询和属性范围查询的自由组合。
当有订单发生变化时，它不仅仅会影响全服状态下搜索和推荐条件的结果变化，也会同时影响商品维度的聚合，交易行层面的数据聚合。

为了降低搜索开销和提供弹性伸缩的能力，我们在多个不同类型的服务上设计了基于视图的动态索引支持，并且针对常用的一些搜索推荐模型，实现了大量的静态索引。

这也同时带来的影响是每当订单有变化时它都有可能会去刷新大量的索引。我们早期第一版直接用 `std::shared_ptr` 来维护订单信息。每次变更索引时都是重新入删除和插入一个 `std::shared_ptr` 。
`std::shared_ptr` 底层的实现是使用 `std::atomic` 来维护了引用计数。每次变更操作都会导致 `std::atomic` 增减，同时带来 CPU Cache Line 失效。

在大多数场景下，这也没太大问题，因为大多数场景下参数传递 `std::shared_ptr` 也好，内存存放 `std::shared_ptr` 也好，通常上下文会存在更多逻辑操作，导致这个CPU Cache Line 失效后重新prefetch的开销占比很小。但是在我们这个场景下情况又有所不同。
我们采用了BTree来管理有序索引，这样比常规的红黑树来说内存结构会更紧凑，缓存命中率更高。然而在连续大量索引发生变化时，一直要发生Cache失效->重新prefetch，Cache失效->重新prefetch的过程。
这反而带来了额外的浪费。我们在后来用valgrind分析的过程中也确实验证导这部分的Cache Miss率明显高于其他操作。于是实现一个非线程安全版本的 `shared_ptr` 就被提上了日程。思路其实和 Rust的 [std::rc::Rc][1] 很像。

> 其实GCC的 STL本身自带费线程安全的内部版本的，可以通过使用
>
> ```cpp
> template<class T>
> using strong_rc_ptr<T> = std::__shared_ptr<T, std::_S_single>;
> ```
>
> 然后使用 `strong_rc_ptr<T>` 就是单线程模式。然而我们这里考虑到跨编译器跨平台，所以自己实现了一个。

## 实现

### 基础功能

引用计数型的智能指针的基本原理比较简单。就是有一个存储区去存放引用计数。当计数清零后释放。

为了加快解引用的性能，原始指针并没有放在引用计数的存储区里，而是直接放在智能指针对象上。这样大多数场景访问指针内容的时候不需要多一次跳转去查询实际地址。

接下来更多的代码其实是在适配和优化各种使用场景。

+ enable_shared_from_this 的两种实现
+ const类型比较操作符
+ std::shared_ptr 和 boost::shared_ptr 的差异

```cpp
// boost::shared_ptr
class shared_count
{
private:
  sp_counted_base * pi_;

public:
  BOOST_CONSTEXPR shared_count() BOOST_SP_NOEXCEPT: pi_(0)
#if defined(BOOST_SP_ENABLE_DEBUG_HOOKS)
      , id_(shared_count_id)
#endif
  {
  }

  long use_count() const BOOST_SP_NOEXCEPT {
    return pi_ != 0? pi_->use_count(): 0;
  }
};

// GCC: std::shared_ptr
template<_Lock_policy _Lp = __default_lock_policy>
class _Sp_counted_base : public _Mutex_base<_Lp> {
public:
  _Sp_counted_base() noexcept : _M_use_count(1), _M_weak_count(1) { }

  long _M_get_use_count() const noexcept {
    // No memory barrier is used here so there is no synchronization
    // with other threads.
    return __atomic_load_n(&_M_use_count, __ATOMIC_RELAXED);
  }
};

// 单元测试
util::memory::strong_rc_ptr<int> pi;
// boost::shared_ptr 行为（strong_rc_ptr采用此行为）
CASE_EXPECT_TRUE(pi.use_count() == 0);
// std::shared_ptr 行为
CASE_EXPECT_TRUE(pi.use_count() == 1);

pi.reset(static_cast<int *>(nullptr));
CASE_EXPECT_TRUE(pi.use_count() == 1);
```

**操作符的怪异行为**

```cpp
/// GCC: libstdc++
template<typename _Tp1, typename _Tp2, _Lock_policy _Lp>
inline bool operator==(const __shared_ptr<_Tp1, _Lp>& __a, const __shared_ptr<_Tp2, _Lp>& __b) noexcept {
  return __a.get() == __b.get();
}
#ifdef __cpp_lib_three_way_comparison
template<typename _Tp, typename _Up, _Lock_policy _Lp>
inline strong_ordering operator<=>(const __shared_ptr<_Tp, _Lp>& __a, const __shared_ptr<_Up, _Lp>& __b) noexcept {
  return compare_three_way()(__a.get(), __b.get());
}
// 其他相似的重载不再展示 ...
#else
template<typename _Tp, typename _Up, _Lock_policy _Lp>
inline bool operator<(const __shared_ptr<_Tp, _Lp>& __a, const __shared_ptr<_Up, _Lp>& __b) noexcept {
  using _Tp_elt = typename __shared_ptr<_Tp, _Lp>::element_type;
  using _Up_elt = typename __shared_ptr<_Up, _Lp>::element_type;
  using _Vp = typename common_type<_Tp_elt*, _Up_elt*>::type;
  return less<_Vp>()(__a.get(), __b.get());
}
// 其他相似的重载不再展示 ...
#endif

// boost::shared_ptr
template<class T, class U>
inline bool operator==(shared_ptr<T> const & a, shared_ptr<U> const & b) BOOST_SP_NOEXCEPT {
  return a.get() == b.get();
}

template<class T, class U>
inline bool operator<(shared_ptr<T> const & a, shared_ptr<U> const & b) BOOST_SP_NOEXCEPT {
    return a.owner_before(b);
}

// 单元测试
{
  util::memory::strong_rc_ptr<int> p1;
  util::memory::strong_rc_ptr<int> p2;
  p2.reset(nullptr);

  CASE_EXPECT_TRUE(p1 == p2);

  // std::shared_ptr 行为（strong_rc_ptr采用此行为）
  CASE_EXPECT_FALSE((p1 < p2 || p2 < p1>));
  // boost::shared_ptr 行为
  CASE_EXPECT_TRUE((p1 < p2 || p2 < p1>));
}
```

+ 继承和父子转换和比较操作符

```cpp
struct X {
  int dummy;
};

struct Y {
  int dummy2;
};

struct Z : public X, public virtual Y {};

// 单元测试
util::memory::strong_rc_ptr<Z> pz(new Z);
util::memory::strong_rc_ptr<X> px(pz);

CASE_EXPECT_TRUE(px.get() == pz.get());
CASE_EXPECT_TRUE(px == pz);

util::memory::strong_rc_ptr<Y> py(pz);

CASE_EXPECT_TRUE(py.get() == pz.get());
CASE_EXPECT_TRUE(py == pz);
CASE_EXPECT_FALSE(py < pz || pz < py);

// strong_rc_ptr 行为， std::shared_ptr 不允许编译通过
CASE_EXPECT_TRUE(px < py || py < px);
// boost::shared_ptr 行为，和下面操作符实现相关
CASE_EXPECT_FALSE(px < py || py < px);

util::memory::strong_rc_ptr<void> pvx(px);
util::memory::strong_rc_ptr<void> pvy(py);
util::memory::strong_rc_ptr<void> pvz(pz);

CASE_EXPECT_TRUE(pvx.get() != pvy.get());
CASE_EXPECT_TRUE(pvx != pvy);

// std::shared_ptr 行为（strong_rc_ptr采用此行为）
CASE_EXPECT_TRUE(pvx < pvy || pvy < pvx);
CASE_EXPECT_TRUE(pvy < pvz || pvz < pvy);

// boost::shared_ptr 行为，和下面操作符实现相关
CASE_EXPECT_FALSE(pvx < pvy || pvy < pvx);
CASE_EXPECT_FALSE(pvy < pvz || pvz < pvy);
```

## 单元测试

+ boost

## 周边组件迁移

+ 一键切换组件
+ jeffies_timer
+ lru_map
+ WAL模块
+ Excel读表工具兼容性

## 效果

其实在完成之前，其实我们也不确定到底能带来多大的提升。简单的循环benchmark其实也没啥意义，因为和实际使用场景的访问情况相差太远了。

我们在完成之后对我们实际项目路14-16个静态索引的交易行上下架请求和搜索的场景做了对比，大概比 `std::shared_ptr` 提升了10%-16%的综合性能，这里面其实附带了其他的一些视图和索引的比较操作和其他RPC的操作。所以单单这个智能指针的部分提升应该是更大的。

## 未来规划

之前实现 [libcopp][2] 对C++20协程支持的时候也有几处内部生命周期引用的地方是计划中后续改成无Cache Miss的版本的，后续看有空也改造一下吧。也是能减少一些不必要的内部开销。

我们也在继续逐渐把一些本来也不是线程安全的模块都换成新智能指针，欢迎有兴趣的小伙伴互相交流研究。

[1]: https://doc.rust-lang.org/std/rc/struct.Rc.html
[2]: https://github.com/owent/libcopp
