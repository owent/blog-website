<!doctype html><html lang=zh-cn><head><meta charset=utf-8><title>std::condition_variable 的信号丢失问题|I'm OWenT</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><link rel=canonical href=//owent.net/2024/2403.html><link rel=icon href=/favicon.ico><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap/dist/css/bootstrap.min.css crossorigin=anonymous><link rel=stylesheet href=//owent.net//css/style.css><link rel=stylesheet href=//owent.net/css/syntax.css><script type=importmap>
{
  "imports": {
    "react": "https://cdn.jsdelivr.net/npm/react/+esm",
    "react-bootstrap": "https://cdn.jsdelivr.net/npm/react-bootstrap/+esm",
    "mermaid": "https://cdn.jsdelivr.net/npm/mermaid/+esm",
    "bootstrap": "https://cdn.jsdelivr.net/npm/bootstrap/+esm",
    "@popperjs/core": "https://cdn.jsdelivr.net/npm/popper.js/+esm"
  }
}
</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8180054975285991" crossorigin=anonymous></script><meta content="codeva-4M5iohb9TW" name=baidu-site-verification></head><body><div id=container><div id=wrap><header id=header><div id=banner></div><div id=header-outer><div id=header-title><h1 id=site-title><a href=//owent.net/ id=logo>I'm OWenT</a></h1><h2 id=site-description>Challenge Everything</h2></div><div id=header-inner><nav id=main-nav class="navbar navbar-expand-md navbar-dark"><button class="navbar-toggler navbar-toggler-right" type=button data-bs-toggle=collapse data-bs-target=#main-nav-links aria-controls=main-nav-links aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span>
</button>
<a id=main-nav-brand class="navbar-brand collapse" href=#>#</a><div class="collapse navbar-collapse position-relative" id=main-nav-links><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/index.html title=Home>Home</a></li><li class=nav-item><a class=nav-link href=/archives/index.html title=Archives>Archives</a></li><li class=nav-item><a class=nav-link href=/about/index.html title=About>About</a></li></ul><div class="col-12 col-xl-2 col-lg-3 col-md-4" id=main-nav-search><form class=input-group method=get accept-charset=UTF-8 action=//www.bing.com/search><input type=hidden name=q1 value=site:owent.net>
<input class=form-control type=text placeholder=搜索 name=q>
<button class="btn btn-outline-secondary my-0" type=submit>搜索</button></form></div></div></nav></div></div></header><div id=main><section id=main-content><div id=post-content><article id=post-69b8f97865369bf0689638875b09668c class="article-panel article article-type-post" itemscope itemprop=blogPost><div class="article-panel-inner article-inner"><div class=article-inner><header class=article-header><h1 itemprop=name><a class=article-title href=//owent.net/2024/2403.html target=_blank itemprop=url>std::condition_variable 的信号丢失问题</a></h1></header><hr><div id=toc class="well toc m-3 p-1 pr-1 pt-1 pb-2 float-md-right float-md-end"><nav id=TableOfContents><ul><li><a href=#背景>背景</a></li><li><a href=#相关代码和使用场景>相关代码和使用场景</a></li><li><a href=#问题分析>问题分析</a></li><li><a href=#解决方案>解决方案</a></li><li><a href=#后续问题>后续问题</a></li></ul></nav><div class="ads-placeholder ads-container"><ins class="adsbygoogle ads_toc" style=display:block data-ad-client=ca-pub-8180054975285991 data-ad-slot=1249494377 data-ad-format="rectangle, vertical" data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div><br><div class=article-entry itemprop=articleBody><h2 id=背景>背景</h2><p>这篇分享拖更了好久了。问题起源于去年我们项目组接入 <a href=https://github.com/open-telemetry/opentelemetry-cpp>opentelemetry-cpp</a> 的时候，在进程优雅退出的时候偶现超时，虽然可以直接kill进程没啥影响但是退出不“优雅”的话总归会破坏发布流程，增加人工介入的成本。这里记录一下问题可能其他的组件有类似的用法也会有相似的问题。</p><h2 id=相关代码和使用场景>相关代码和使用场景</h2><p>首先介绍下代码逻辑的背景，在代码结构层面。首先是有一个后台线程处理Batch Process和导出任务。然后caller线程发起 <code>ForceFlush</code> 或者 <code>Shutdown</code> 的时候要等待已经发出的事件执行完毕。
他们之间通过 <code>std::condition_variable</code> 来通知事件完成。</p><p>大致代码如下,首先是 <code>bool BatchSpanProcessor::ForceFlush(std::chrono::microseconds timeout) noexcept</code> 接口:</p><pre><code class=language-cpp>bool BatchSpanProcessor::ForceFlush(std::chrono::microseconds timeout) noexcept
{
  // ...

  // Now wait for the worker thread to signal back from the Export method
  std::unique_lock&lt;std::mutex&gt; lk_cv(synchronization_data_-&gt;force_flush_cv_m);

  synchronization_data_-&gt;is_force_flush_pending.store(true, std::memory_order_release);
  auto break_condition = [this]() {
    if (synchronization_data_-&gt;is_shutdown.load() == true)
    {
      return true;
    }

    // Wake up the worker thread once.
    if (synchronization_data_-&gt;is_force_flush_pending.load(std::memory_order_acquire))
    {
      synchronization_data_-&gt;is_force_wakeup_background_worker.store(true,
                                                                     std::memory_order_release);
      synchronization_data_-&gt;cv.notify_one();
    }

    return synchronization_data_-&gt;is_force_flush_notified.load(std::memory_order_acquire);
  };

  // Fix timeout to meet requirement of wait_for
  timeout = opentelemetry::common::DurationUtil::AdjustWaitForTimeout(
      timeout, std::chrono::microseconds::zero());
  bool result;
  if (timeout &lt;= std::chrono::microseconds::zero())
  {
    bool wait_result = false;
    while (!wait_result)
    {
      // When is_force_flush_notified.store(true) and force_flush_cv.notify_all() is called
      // between is_force_flush_pending.load() and force_flush_cv.wait(). We must not wait
      // for ever
      wait_result = synchronization_data_-&gt;force_flush_cv.wait_for(lk_cv, schedule_delay_millis_,
                                                                   break_condition);
    }
    result = true;
  }
  else
  {
    result = synchronization_data_-&gt;force_flush_cv.wait_for(lk_cv, timeout, break_condition);
  }

  // ...
  return result;
}
</code></pre><p>然后 <code>void BatchSpanProcessor::DoBackgroundWork()</code> 和相关代码:</p><pre><code class=language-cpp>void BatchSpanProcessor::DoBackgroundWork()
{
  auto timeout = schedule_delay_millis_;

  while (true)
  {
    // Wait for `timeout` milliseconds
    std::unique_lock&lt;std::mutex&gt; lk(synchronization_data_-&gt;cv_m);
    synchronization_data_-&gt;cv.wait_for(lk, timeout, [this] {
      if (synchronization_data_-&gt;is_force_wakeup_background_worker.load(std::memory_order_acquire))
      {
        return true;
      }

      return !buffer_.empty();
    });
    synchronization_data_-&gt;is_force_wakeup_background_worker.store(false,
                                                                   std::memory_order_release);

    if (synchronization_data_-&gt;is_shutdown.load() == true)
    {
      DrainQueue();
      return;
    }

    auto start = std::chrono::steady_clock::now();
    Export();
    auto end      = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(end - start);

    // Subtract the duration of this export call from the next `timeout`.
    timeout = schedule_delay_millis_ - duration;
  }
}

void BatchSpanProcessor::Export()
{
  do
  {
    // 省略无关代码 ...
    exporter_-&gt;Export(nostd::span&lt;std::unique_ptr&lt;Recordable&gt;&gt;(spans_arr.data(), spans_arr.size()));
    NotifyCompletion(notify_force_flush, synchronization_data_);
  } while (true);
}

void BatchSpanProcessor::NotifyCompletion(
    bool notify_force_flush,
    const std::shared_ptr&lt;SynchronizationData&gt; &amp;synchronization_data)
{
  if (!synchronization_data)
  {
    return;
  }

  if (notify_force_flush)
  {
    synchronization_data-&gt;is_force_flush_notified.store(true, std::memory_order_release);
    synchronization_data-&gt;force_flush_cv.notify_one();
  }
}
</code></pre><p>简单描述一下就是在退出阶段，首先要设置shutdown flag，然后唤醒后台线程导出数据。之后用一个 <code>std::condition_variable</code> 来等待后台线程通知导出完成。然后自己再退出，时序大概如下:</p><pre><code class=language-{mermaid}>sequenceDiagram
    Caller-&gt;&gt;Caller: 采集当前待上报边界
    Background-&gt;&gt;Background: 启动
    Caller-&gt;&gt;Background: 通知唤醒后台线程(condition_variable-1)
    Caller-&gt;&gt;Caller: 进入等待上报完成通知(condition_variable-2)
    loop 循环执行到退出
    Background-&gt;&gt;Background: 导出一批数据
    Background-&gt;&gt;Caller: 通知已经导出的数据边界(condition_variable-2)
    Background-&gt;&gt;Background: 没有数据则进入等待(condition_variable-1)
    end
    loop 直到当前上报边界已经全部上报完成或超时
      Caller-&gt;&gt;Caller: 等待上报完成唤醒(condition_variable-2)
      Caller-&gt;&gt;Caller: 检查上报边界或超时
    end
    Caller-&gt;&gt;Caller: 退出
    Background-&gt;&gt;Background: 后台线程退出
</code></pre><h2 id=问题分析>问题分析</h2><p>上面的流程和代码乍一看似乎没有什么问题，但是在实际项目中偶尔会出现在 <code>BatchSpanProcessor::ForceFlush</code> 里的 <code>synchronization_data_->force_flush_cv.wait_for</code> 陷入了长耗时的等待。有的版本甚至会陷入无尽得等待。</p><p>因为在退出流程里，上层要保证最后的数据执行过刷出。并且后台线程不再引用资源之后才能销毁内存对象，所以会<code>ForceFlush</code> 一次，且 <code>schedule_delay_millis_</code> 一般情况下考虑网络抖动会设置得比较长。某些流程里也有可能会在reload的时候切换到另一个新线程上调用 <code>ForceFlush(max())</code> 的，这时候如果发生退出也会发生某些Provider一直退不掉的问题。</p><p>在后台任务刷出数据完成后，设置完 <code>is_force_flush_notified</code> 并且 <code>force_flush_cv.notify_one()</code> 后下一此循环会发现 <code>is_shutdown</code> 已经是 <code>true</code> 了，就会退出后台线程，之后就不再有 <code>force_flush_cv.notify_one()</code> 了。</p><p>那么在调用 <code>ForceFlush()</code> 的线程里 <code>force_flush_cv.wait_for(lk_cv, schedule_delay_millis_, break_condition);</code> 的 <code>break_condition</code> 包含 <code>is_force_flush_notified.load(std::memory_order_acquire);</code> 为什么返回 <code>false</code> 且后面还没收到 <code>force_flush_cv.notify_one()</code> 的通知呢？</p><p>我们先来看一看 <code>std::condition_variable::wait_for</code> 的实现。（几个主流STL库实现大同小异，这里贴Linux下GCC的实现作为案例）</p><pre><code class=language-cpp>template&lt;typename _Rep, typename _Period, typename _Predicate&gt;
  bool
  wait_for(unique_lock&lt;mutex&gt;&amp; __lock,
      const chrono::duration&lt;_Rep, _Period&gt;&amp; __rtime,
      _Predicate __p)
  {
using __dur = typename steady_clock::duration;
return wait_until(__lock,
    steady_clock::now() +
    chrono::__detail::ceil&lt;__dur&gt;(__rtime),
    std::move(__p));
  }

template&lt;typename _Clock, typename _Duration, typename _Predicate&gt;
  bool
  wait_until(unique_lock&lt;mutex&gt;&amp; __lock,
  const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __atime,
  _Predicate __p)
  {
while (!__p())
if (wait_until(__lock, __atime) == cv_status::timeout)
  return __p();
return true;
  }

  // 其他的 wait_until 嵌套都是设计模式相关，不在展示，最后是调用下面的代码,pthread的接口
  void
  wait_until(mutex&amp; __m, clockid_t __clock, timespec&amp; __abs_time)
  {
    pthread_cond_clockwait(&amp;_M_cond, __m.native_handle(), __clock,
          &amp;__abs_time);
  }
</code></pre><p>可以看到，这里关键点在这个代码:</p><pre><code class=language-cpp>while (!__p())
if (wait_until(__lock, __atime) == cv_status::timeout)
  return __p();
return true;
</code></pre><p>可能会存在一个极小的临界区，在调用 <code>__p()</code> 的时候 <code>is_force_flush_notified.store(true, std::memory_order_release)</code> 和 <code>force_flush_cv.notify_one()</code> 还没执行到，然后准备进入 <code>wait_until(__lock, __atime)</code>, 但是在最终调用 <code>pthread_cond_clockwait</code> 前 <code>is_force_flush_notified.store(true, std::memory_order_release)</code> 和 <code>force_flush_cv.notify_one()</code> 执行掉了。然后再进入wait就没收到 notify ，并且由于退出阶段，后台线程已经退出不会再收到新的notify，所以必须等待到超时。如果这时候超时时间很长就会陷入一个非常长时间的等待。</p><h2 id=解决方案>解决方案</h2><p>找到问题之后解决方法就比较简单了。主要有两种，一种是再加一个 mutex 锁，把 <code>is_force_flush_notified</code> ， <code>force_flush_cv</code> 和 <code>std::condition_variable::wait_for</code> 也放进这个锁的临界区里保护，这样会多一个锁，多一些额外开销。另一种方案则是缩短等待时间后重试，缺点是发生这个情况的时候可能要多等个这个等待时间后才能完成。</p><p>因为这个毕竟是在退出阶段才出现且很小概率出现，所以我选了后一种不带来额外开销的方案。PR去年已经合入，小伙伴门可以放心使用。</p><h2 id=后续问题>后续问题</h2><p>后面其实还有线程安全的问题也和这个相关，虽然我们项目里没用到，但是社区收到了issue。因为上面的 <code>is_force_flush_notified</code> 是个atomic的bool值，在多线程调用 <code>ForceFlush()</code> 的时候有概率某个线程的 <code>is_force_flush_notified</code> 会被其他线程吞掉。相关详情见: <a href=https://github.com/open-telemetry/opentelemetry-cpp/issues/2574>[SDK] BatchSpanProcessor::ForceFlush appears to be hanging forever</a> 和 <a href=https://github.com/open-telemetry/opentelemetry-cpp/issues/2583>[SDK] BatchLogRecordProcessor::ForceFlush hangs for 10 seconds</a> 。
现在的解决法方法是不再使用bool值判定多次调用的先后关系，而是使用exported序号来进行。PR见: <a href=https://github.com/open-telemetry/opentelemetry-cpp/pull/2584>[SDK] Fix forceflush may wait for ever</a>。</p><p>欢迎有兴趣的小伙伴互相交流研究。</p></div><hr><footer class=article-footer><div class="article-panel-footer article-meta article-footer clearfix"><span class=article-meta-left><ol><li><a href=//owent.net/categories/article.html>Article</a></li><li><a href=//owent.net/categories/blablabla.html>Blablabla</a></li></ol></span><span class=article-meta-right><time datetime=2024-08-02T15:30:45.000+00:00 itemprop=datePublished>2024-08-02</time></span>
<span class=clearfix></span></div><div class=article-tags><ul class=article-tag-list><li class=article-tag-list-item><a href=//owent.net/tags/cpp.html>cpp</a></li><li class=article-tag-list-item><a href=//owent.net/tags/cxx.html>cxx</a></li><li class=article-tag-list-item><a href=//owent.net/tags/opentelemetry.html>opentelemetry</a></li><li class=article-tag-list-item><a href=//owent.net/tags/condition_variable.html>condition_variable</a></li><li class=article-tag-list-item><a href=//owent.net/tags/notify.html>notify</a></li></ul></div></footer><div class="ads-placeholder ads-container"><ins class="adsbygoogle ads_infeed" style=display:block data-ad-client=ca-pub-8180054975285991 data-ad-slot=5599802929 data-ad-format="rectangle, horizontal" data-full-width-responsive=true></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div><hr><nav id=article-nav><ul class=pagination><li class=page-item><a class=page-link id=article-nav-newer class=article-nav-link-wrap href=//owent.net/2024/2404.html>上一篇<strong>手夯一个STL allocator和对象内存分析组件</strong></a></li><li class=page-item><a class=page-link id=article-nav-older class=article-nav-link-wrap href=//owent.net/2024/2402.html>下一篇<strong>踩坑一处（GCC）STL `std::async` 实现BUG导致的crash问题</strong></a></li></ul></nav><hr><script src=https://utteranc.es/client.js repo=owent/blog-website issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></article></div></section></div><footer id=footer><div class=outer><div id=footer-info class="inner clearfix"><strong id=footer-left class="float-left float-start"><a rel=license href=https://github.com/owent/blog-hugo/blob/master/LICENSE.md><img alt=知识共享许可协议 style=border-width:0 src=https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png></a>2025&nbsp;owent
</strong><strong id=footer-right class="float-right float-end"><a href=https://beian.miit.gov.cn/ target=_blank>沪ICP备2022003252号</a>&nbsp;&nbsp;<a href=https://github.com/owent/blog-hugo target=_blank>本站源码</a>,
发布者 <a href=https://gohugo.io/ target=_blank>Hugo</a>,
主题 <a href=https://github.com/owent/hugo-theme-distinctionpp target=_blank>distinctionpp</a>
</strong><span class=clearfix></span></div></div></footer></div><script type=module>// import * as Popper from "@popperjs/core";// import * as bootstrap from "bootstrap";
// import React from "react";

        
</script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/highlight.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/accesslog.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/armasm.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/awk.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/basic.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/bnf.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/capnproto.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/cmake.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/d.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/dockerfile.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/dos.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/erlang.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/ebnf.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/latex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/llvm.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/lua.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/powershell.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/protobuf.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/profile.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/vim.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/x86asm.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/languages/yaml.min.js></script><script type=text/javascript>document.addEventListener("DOMContentLoaded",e=>{const t=document.createElement("link");t.rel="stylesheet",t.href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/styles/vs2015.min.css",document.querySelector("head").appendChild(t),window.JSON?hljs.configure(JSON.parse('{"ignoreunescapedhtml":true,"languages":{},"tabreplace":"    ","throwunescapedhtml":false,"usebr":false}')):hljs.configure(evel('{"ignoreunescapedhtml":true,"languages":{},"tabreplace":"    ","throwunescapedhtml":false,"usebr":false}'));const n={};for(const e of hljs.listLanguages())n[e.toLowerCase()]=!0;for(const e of document.querySelectorAll("pre>code"))try{if(e.className.match(/\bmermaid\b/i)){e.classList.add("mermaid");continue}if(e.className.match(/\bnohighlight\b/i))continue;const t=e.className.match(/language-([^\s]+)/i);if(t&&t.length>=2&&hljs.getLanguage(t[1]))hljs.highlightElement(e);else{const t=hljs.highlightAuto(e.innerText,hljs.listLanguages());t&&t.value&&(e.innerHTML=t.value,e.classList.add("hljs"))}}catch(e){window.console&&console.log(e.toString()+`\r
Maybe can not detect the language`)}})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-PQEY77BYG1"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PQEY77BYG1")}</script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex/dist/contrib/auto-render.min.js></script><script type=text/javascript>document.addEventListener("DOMContentLoaded",e=>{const t=document.createElement("link");t.rel="stylesheet",t.href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css",document.querySelector("head").appendChild(t),renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!1,ignoredTags:["script","noscript","style","textarea","pre","code"]})})</script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/chart.js/dist/chart.umd.min.js></script><script type=module>
import mermaid from "mermaid";
const config = {
    theme: 'neutral',
    logLevel: 'fatal',
    securityLevel: 'loose', 
    startOnLoad: true,
    arrowMarkerAbsolute: false,
    

};
mermaid.initialize(config);
</script><script type=text/javascript>var _hmt=_hmt||[];(function(){var t,n,e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6a0daf8d58889f1cf55a353867bfdbb0",t=document.getElementsByTagName("script"),n=document.getElementsByTagName("script")[t.length-1],n.parentNode.appendChild(e)})()</script></div></body></html>