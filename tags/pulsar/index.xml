<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Pulsar on I'm OWenT</title><link>//owent.net/tags/pulsar.html</link><description>Recent content in Pulsar on I'm OWenT</description><generator>Hugo</generator><language>zh-cn</language><copyright>&lt;a rel="license" href="https://github.com/owent/blog-hugo/blob/master/LICENSE.md">&lt;img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" />&lt;/a></copyright><lastBuildDate>Sat, 17 Nov 2018 02:00:00 +0000</lastBuildDate><atom:link href="//owent.net/tags/pulsar/index.xml" rel="self" type="application/rss+xml"/><item><title>使用ELK辅助监控开发测试环境服务质量和问题定位</title><link>//owent.net/2018/1812.html</link><pubDate>Sat, 17 Nov 2018 02:00:00 +0000</pubDate><guid>//owent.net/2018/1812.html</guid><description>&lt;h2 id="什么是elk">什么是ELK？&lt;/h2>
&lt;p>ELK 是 &lt;a href="https://www.elastic.co/cn/products/elasticsearch">elasticsearch&lt;/a> + &lt;a href="https://www.elastic.co/cn/products/logstash">logstash&lt;/a> + &lt;a href="https://www.elastic.co/cn/products/kibana">kibana&lt;/a>的缩写。这一套是现在比较流行的日志全文索引系统了。我之前的项目也有用它来做过日志分析，这次主要是拿来搭建开发测试环境的监控和分析系统，顺带记录一下部署脚本和流程。&lt;/p>
&lt;p>其中 &lt;a href="https://www.elastic.co/cn/products/elasticsearch">elasticsearch&lt;/a> 是日志索引系统，我按两个master，3个数据和处理节点来部署。 &lt;a href="https://www.elastic.co/cn/products/logstash">logstash&lt;/a> 和 &lt;a href="https://www.elastic.co/cn/products/kibana">kibana&lt;/a> 因为是开发测试环境使用，量级不大，所以只部署了一个节点。但是在使用过程中发现 &lt;a href="https://www.elastic.co/cn/products/elasticsearch">elasticsearch&lt;/a> 在jre的GC的时候还是有较长时间的 &lt;em>&lt;strong>Stop The World&lt;/strong>&lt;/em> 的问题，而且这期间的数据会倍丢弃。所以为了缓解这个状况，又引入了 &lt;a href="https://redis.io/">redis&lt;/a> 作为消息队列使用。然后使用两组pipeline，一个从 client -&amp;gt; &lt;a href="https://www.elastic.co/cn/products/logstash">logstash&lt;/a> -&amp;gt; &lt;a href="https://redis.io/">redis&lt;/a> ，另一个从 &lt;a href="https://redis.io/">redis&lt;/a> -&amp;gt; &lt;a href="https://www.elastic.co/cn/products/logstash">logstash&lt;/a> -&amp;gt; &lt;a href="https://www.elastic.co/cn/products/elasticsearch">elasticsearch&lt;/a> 来传输。这样如果在 &lt;a href="https://www.elastic.co/cn/products/elasticsearch">elasticsearch&lt;/a> GC的 &lt;em>&lt;strong>Stop The World&lt;/strong>&lt;/em> 结束的时候会把数据补回去。 外面更大型的部署也有用 &lt;a href="https://kafka.apache.org/">kafka&lt;/a> 或者更进一步优化的 &lt;a href="https://pulsar.apache.org/">pulsar&lt;/a>。不过我们目前的应用也不太需要 &lt;a href="https://kafka.apache.org/">kafka&lt;/a> 和 &lt;a href="https://pulsar.apache.org/">pulsar&lt;/a> 那种数据落地和强一致性，使用 &lt;a href="https://redis.io/">redis&lt;/a> 也已经够了。&lt;/p></description></item></channel></rss>