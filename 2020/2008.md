---
author: owent
categories:
  - Article
  - Blablabla
date: 2020-10-13 12:19:45
draft: true
id: 2008
tags: 
  - aurora
  - database
  - distributed
title: Amazon Aurora论文阅读小计
type: post
---


主要就看了两篇Paper， [《Amazon Aurora - Design Considerations for High Throughput Cloud-Native Relational Databases》][1] 是一个整体性质的介绍和概述。 [《Amazon Aurora: On Avoiding Distributed Consensus for I/Os,Commits, and Membership Changes》][6] 是对其重点部分的存储服务的

+ 6个副本，4节点确认写，三节点确认读。三DC(Amazon Zone)部署。
  + 一个DC灾害并且引起容灾抖动的情况，可持续服务
  + [**Read Your Writes**][2] 的扩展
  + 保证在一个节点升级的时候，如果有一个DC(Amazon Zone)发生天灾，读服务仍然可用
+ 使用REDO日志存储，和redis一样（容易复制，容易补空洞）
+ 使用递增的LSN(Log Sequence Number)处理冲突（补偿策略）
+ 区分Writer和Peplicator，仅Writer可能出现undo操作（MVCC）

存储层:

+ 日志按PG分组(Protection  Groups),每个PG 10GB
+ 不需要2PC，容灾和故障恢复直接复制PG
+ gossip协议同步和填补WAL空洞
+ 定义VCL(Volume Complete LSN)标识本地已经完成执行的事务Log序号
+ 定义VDL(Volume Durable LSN)标识本地已经完成持久化的事务Log序号。 \\\( VDL<=VCL \\\)

Write:

+ 定义LAL(LSN  Allocation  Limit)用于控制执行队列的最大长度（1千万）。 \\\( max(SLN) <= VDL+VCL \\\)
+ 每个PG定义一个SCL(Segment  Complete  LSN)标识已经完成的Log序号
+ 每个Log记录上一条同PG的Log索引，构成链表
+ 合包策略和 [atbus][7] 一样


Commit:

+ 递增VDL即可
+ 专有线程用于回复客户端

Read:

+ 带本地Page缓存，本地缓存的LSN总是小于等于VDL，所以缓存淘汰和换入直接替换即可，不存在落地和一致性问题
+ 定义PGMRPL(per-PG Minimum Read Point LSN)，标识每个PG的Minimum  Read  Point  LSN。即这个值之前的所有Log都已经同步到所有的副本。
+ 维护执行中的事务队列，小于PGMRPL的事务可以被GC
+ 使用gossip协议同步PGMRPL
+ 使用VDL来同步Read View

容灾:

1. 新增一个副本（比如ABCDEF中F故障，新增副本G。把然后把副本分为两组，ABCDEF和ABCDEG）
2. 在同步和迁移过程中，对写操作，要求所有副本组都满足 4/6 确认。（即ABCDEF和ABCDEG中都必须至少有4个确认）
3. 在同步和迁移过程中，对读操作，要求任一副本组满足 3/6 确认。（即ABCDEF和ABCDEG中只要一组有3个确认即可）
4. 等迁移完毕，移除副本F

流程如下:

![2008-failure.png](2008-failure.png)

如果在这过程中又有节点失败，则同时要满足以上规则里两个副本迁移的条件。比如在上述流程中E节点又故障了。

1. 新增副本H；
2. 在同步和迁移过程中，对于写操作，需要ABCDEF和ABCDEG中副本都满足 4/6 确认，且ABCDFH和ABCDGH中副本都满足 4/6 确认。

其他:

+ 事务处理Fork的社区版MySQL的InnoDB，替换了WAL的读写部分。
  + MySQL原来的持久化是执行事务时落地redo log，使用Double-Write技术防止脏页。
  + Aurora中所有的日志都是按PG共享，由存储服务提供。
+ 写数据的隔离性和社区版MySQL一致
+ 个人理解读和镜像隔离性依赖InnoDB内的B+树+共享的redo log
+ 整体设计特别适合 [LSM Tree][5]
+ GC策略: 可以安全回收PGMRPL(per-PG Minimum Read Point LSN)之前的Log
+ 写放大优化(Full Segments/Tail Segments)。八6倍放大优化到3倍。
  + Redo Log数据相对较小（因为PGMRPL之前的部分是可以直接回收的，这个窗口很小）。全量数据比较大。
  + 把副本分为Full Segments和Tail Segments，3个Full Segments副本和3个Tail Segments副本
    > Full Segments中包含全量数据和Redo Log，Tail Segments只包含Redo Log
  + 写确认改为4/6副本或3/3 Full Segments副本确认
  + 读确认改为3/6副本确认或1/3 Full Segments副本确认
  + 容灾和故障切换中Full Segments副本需要先从其他Full Segments副本同步快照，然后从其他Tail Segments副本中同步Redo Log。
    > 针对: 写操作中 1/3 Full Segments副本和 3/3 Tail Segments副本确认的情况

性能:

使用Amazon EC2实例，实例类型为R3(内存优化型)

> CPU: 32 vCPUs(Xeon E5-2670 v2)
> Memory: 244GB

![2008-sysbench-read-only.png](2008-sysbench-read-only.png)

![2008-sysbench-write-only.png](2008-sysbench-write-only.png)

几乎拥有线性扩展能力。

Table 2: SysBench Write-Only (writes/sec)

| DB Size | Amazon Aurora | MySQL |
|---------|---------------|--------|
| 1 GB    | 10700         | 8400  |
| 10GB    | 107000        | 2400  |
| 100 GB  | 101000        | 1500  |
| 1 TB    | 41000         | 1200  |

Table 3: SysBench OLTP(writes/sec)

| Connections | Amazon Aurora | MySQL  |
|-------------|---------------|--------|
| 50          | 40000         | 10000  |
| 500         | 71000         | 21000  |
| 5000        | 111000        | 13000  |

Table 4: Replica Lag for SysBench Write-Only(msec)

| Writes/sec | Amazon Aurora | MySQL  |
|------------|---------------|--------|
| 1000       | 2.62          | < 1000 |
| 2000       | 3.42          | 1000   |
| 5000       | 3.94          | 60000  |
| 10000      | 5.38          | 300000 |

这里解耦并使用的服务化的存储引擎和不需要协商一致性就展现出了副本拷贝延迟的巨大优势。

## 总结

文中也提到了 Google的 [Spanner][4] ，并说 [Spanner][4] 是针对 Google 多读的业务优化的。但是我个人的想法是 [Spanner][4] 的涉及特点是基于时间的，要考虑误差所以延迟比较高。 [Aurora][1] 这种直接基于InnoDB流程的就比较容易有低延迟。但是另一方面对部分式事务的一致性的支持没有 [Spanner][4] 好。

[1]: https://media.amazonwebservices.com/blog/2017/aurora-design-considerations-paper.pdf
[2]: http://www.dbms2.com/2010/05/01/ryw-read-your-writes-consistency/
[3]: http://pages.cs.wisc.edu/~yxy/cs839-s20/papers/aurora-sigmod-18.pdf
[4]: https://ai.google/research/pubs/pub39966
[5]: https://en.wikipedia.org/wiki/Log-structured_merge-tree
[6]: https://dl.acm.org/doi/abs/10.1145/3183713.3196937
[7]: https://github.com/atframework/libatbus
