---
author: owent
categories:
  - Article
  - Blablabla
date: 2020-09-13 12:19:45
draft: true
id: 2007
tags: 
  - aurora
  - database
  - distributed
title: Amazon Aurora论文阅读小计
type: post
---


主要就看了两篇Paper， [《Amazon Aurora - Design Considerations for High Throughput Cloud-Native Relational Databases》][1] 是一个整体性质的介绍和概述。 [《Amazon Aurora: On Avoiding Distributed Consensus for I/Os,Commits, and Membership Changes》][6] 是对其重点部分的存储服务的

+ 6个副本，4节点确认写，三节点确认读。三DC部署。
  + 一个DC灾害并且引起容灾抖动的情况，可持续服务
  + [**Read Your Writes**][2] 的扩展
+ 使用REDO日志存储，和redis一样（容易复制，容易补空洞）
+ 使用递增的LSN(Log Sequence Number)处理冲突（补偿策略）

存储层:

+ 日志按PG分组(Protection  Groups),每个PG 10GB
+ 不需要2PC，容灾和故障恢复直接复制PG
+ gossip协议同步和填补WAL空洞
+ 定义VCL(Volume Complete LSN)标识本地已经完成执行的事务Log序号
+ 定义VDL(Volume Durable LSN)标识本地已经完成持久化的事务Log序号。 \\\( VDL<=VCL \\\)

Write:

+ 定义LAL(LSN  Allocation  Limit)用于控制执行队列的最大长度（1千万）。 \\\( max(SLN) <= VDL+VCL \\\)
+ 每个PG定义一个SCL(Segment  Complete  LSN)标识已经完成的Log序号
+ 每个Log记录上一条同PG的Log索引，构成链表

Commit:

+ 递增VDL即可
+ 专有线程用于回复客户端

Read:

+ 带本地Page缓存，本地缓存的LSN总是小于等于VDL，所以缓存淘汰和换入直接替换即可，不存在落地和一致性问题
+ 定义PGMRPL(per-PG Minimum Read Point LSN)，标识每个PG的Minimum  Read  Point  LSN。即这个值之前的所有Log都已经同步到所有的副本。
+ 维护执行中的事务队列，小于PGMRPL的事务可以被GC
+ 使用gossip协议同步PGMRPL

其他:

+ 事务处理Fork的社区版MySQL的InnoDB，替换了WAL的读写部分。
  + MySQL原来的持久化是执行事务时落地redo log，使用Double-Write技术防止脏页。
  + Aurora中所有的日志都是按PG共享，由存储服务提供。
+ 写数据的隔离性和社区版MySQL一致
+ 个人理解读和镜像隔离性依赖InnoDB内的B+树+共享的redo log
+ 整体设计特别适合 [LSM Tree][5]

性能:

使用Amazon EC2实例，实例类型为R3(内存优化型)

> CPU: 32 vCPUs(Xeon E5-2670 v2)
> Memory: 244GB

![2007-sysbench-read-only.png](2007-sysbench-read-only.png)

![2007-sysbench-write-only.png](2007-sysbench-write-only.png)

几乎拥有线性扩展能力。

Table 2: SysBench Write-Only (writes/sec)

| DB Size | Amazon Aurora | MySQL |
|---------|---------------|--------|
| 1 GB    | 10700         | 8400  |
| 10GB    | 107000        | 2400  |
| 100 GB  | 101000        | 1500  |
| 1 TB    | 41000         | 1200  |

Table 3: SysBench OLTP(writes/sec)

| Connections | Amazon Aurora | MySQL  |
|-------------|---------------|--------|
| 50          | 40000         | 10000  |
| 500         | 71000         | 21000  |
| 5000        | 111000        | 13000  |

Table 4: Replica Lag for SysBench Write-Only(msec)

| Writes/sec | Amazon Aurora | MySQL  |
|------------|---------------|--------|
| 1000       | 2.62          | < 1000 |
| 2000       | 3.42          | 1000   |
| 5000       | 3.94          | 60000  |
| 10000      | 5.38          | 300000 |

这里解耦并使用的服务化的存储引擎和不需要协商一致性就展现出了副本拷贝延迟的巨大优势。

## 总结

文中也提到了 Google的 [Spanner][4] ，并说 [Spanner][4] 是针对 Google 多读的业务优化的。但是我个人的想法是 [Spanner][4] 的涉及特点是基于时间的，要考虑误差所以延迟比较高。 [Aurora][1] 这种直接基于InnoDB流程的就比较容易有低延迟。但是另一方面对部分式事务的一致性的支持没有 [Spanner][4] 好。

[1]: https://media.amazonwebservices.com/blog/2017/aurora-design-considerations-paper.pdf
[2]: http://www.dbms2.com/2010/05/01/ryw-read-your-writes-consistency/
[3]: http://pages.cs.wisc.edu/~yxy/cs839-s20/papers/aurora-sigmod-18.pdf
[4]: https://ai.google/research/pubs/pub39966
[5]: https://en.wikipedia.org/wiki/Log-structured_merge-tree
[6]: https://dl.acm.org/doi/abs/10.1145/3183713.3196937
