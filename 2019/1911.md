---
author: owent
categories:
  - Article
  - Blablabla
date: 2019-09-22 14:25:00
draft: true
id: 1911
tags: 
  - cxx
  - cpp
  - coroutine
  - std
  - iso
  - 协程
  - msvc
  - clang
  - llvm
  - libcxx
  - libc++
  - libcxxabi
  - libc++abi
  - libcopp
title: C++20 Coroutine 性能测试 (附带和libcopp/libco/libgo/goroutine/linux ucontext对比)
type: post
---

前言
------------------------------------------------

之前写了 [《协程框架(libcopp)v2优化、自适应栈池和同类库的Benchmark对比》][6] 和 [《C++20 Coroutine》][5] ，但是一直没写 [C++20 Coroutine][7] 的测试报告。

现在的草案版本比我当时写 [《C++20 Coroutine》][5] 的时候有了一点点更新，[cppreference][9] 上有文档了(https://en.cppreference.com/w/cpp/language/coroutines) 。里面列举的标准文档是[P0912R5][5]，这个文档目前还没完工，详情可以看他的来源[N4775][10]。不过内容上暂时还没有太大的变化。

本来呢，我我以前的理解，以为 [C++20 Coroutine][7] 是无栈式协程，那样的话就没啥好测得了。因为本身不带什么额外开销，并且开销可控。但是上次写 [《C++20 Coroutine》][5] 得时候发现他也是有栈协程，也是要切换上下文得。今天我就照着之前的构造 L1 Cache Miss 的方式来benchmark一波 [C++20 Coroutine][7] 吧。

压力测试机环境
------------------------------------------------

为了方便比较，我更新了一下之前在 [《协程框架(libcopp)v2优化、自适应栈池和同类库的Benchmark对比》][6] 里的测试项目的版本。Windows环境仅仅是为了测试MSVC下的性能，因为GCC还不支持所以Linux下是使用Clang编译的。

| 环境名称                         | 值                                                  |
|----------------------------------|-----------------------------------------------------|
| 系统                             | Linux kernel 3.10.107(Docker)                       |
| CPU                              | Intel(R) Xeon(R) Gold 61xx CPU @ 2.50GHz \* 48      |
| L1 Cache                         | 64Bytes\*64sets\*8ways=32KB                         |
| 系统负载                         | 0.19 0.25 0.27                                      |
| 内存占用                         | 3.5GB(used)/120GB(cached)/114GB(free)               |
| CMake                            | 3.15.2                                              |
| GCC版本                          | 9.2.0                                               |
| Clang版本                        | 9.0.0                                               |
| [Golang][11]版本                 | [1.13.1][12]                             (20190903) |
| [Boost版本][13]([libgo][15]依赖) | [1.71.1][14]                             (20190819) |
| libco版本                        | 03ba1a453c266b76e1c01aa519621ef7db861500 (20190902) |
| libcopp                          | 1.2.0                                    (20190820) |
| [libgo][15]                      | cbdf26bbf568a72e81fdd7ec390ddbcae5d5dd92 (20190822) |


| 环境名称                       | 值                                                  |
|--------------------------------|-----------------------------------------------------|
| 系统                           | Windows 10 Pro 1903 (2019 Sept)                     |
| CPU                            | Intel(R) Core(TM) i7-8700 @ 3.20GHz \* 12           |
| L1 Cache                       | 64Bytes\*64sets\*8ways=32KB                         |
| 系统负载                       | 低于 10%                                            |
| 内存占用                       | 8.2GB(used)/16.7GB(cached)/38.7GB(free)             |
| MSVC版本                       | MSVC v142 - VS 2019 C++ x86/x64 (14.23)             |

测试代码
------------------------------------------------

[C++20 Coroutine][7] 上手比较麻烦，所以测试代码那是真滴长。 ```co_await``` 的原理和 ```co_yield``` 是一样的，只是 ```co_await``` 多了一点点对封装类似 [libcotask][1] 的支持，单纯的上下文切换仅使用 ```co_yield``` 就可以了。这样也更能公平地拿来和其他几个协程库对比。

Clang编译命令: ```$LLVM_CLANG_PREFIX/bin/clang++ -std=c++2a -O2 -g -ggdb -stdlib=libc++ -fcoroutines-ts -lc++ -lc++abi -Wl,-rpath=$LLVM_CLANG_PREFIX/lib/ test.cpp```

MSVC编译命令: ```cl /nologo /O2 /std:c++latest /Zi /MDd /Zc:__cplusplus /EHsc /await test.cpp```

```cpp
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <ctime>
#include <inttypes.h>
#include <stdint.h>
#include <vector>
#include <memory>
#include <iostream>

#include <experimental/coroutine>

#include <chrono>
#define CALC_CLOCK_T std::chrono::system_clock::time_point
#define CALC_CLOCK_NOW() std::chrono::system_clock::now()
#define CALC_MS_CLOCK(x) static_cast<int>(std::chrono::duration_cast<std::chrono::milliseconds>(x).count())
#define CALC_NS_AVG_CLOCK(x, y) static_cast<long long>(std::chrono::duration_cast<std::chrono::nanoseconds>(x).count() / (y ? y : 1))


static std::vector<std::pair<int*, std::experimental::coroutine_handle<> > > g_test_rpc_manager;

struct test_custom_coroutine_data;
struct test_custom_coroutine {
    using data_ptr = std::unique_ptr<test_custom_coroutine_data>;

    struct promise_type {
        data_ptr refer_data;
        char fake_cache_miss_[64 - sizeof(test_custom_coroutine_data*)];
        promise_type();

        static test_custom_coroutine get_return_object_on_allocation_failure();

        test_custom_coroutine get_return_object();

        std::experimental::suspend_always initial_suspend();

        std::experimental::suspend_always final_suspend();

        void unhandled_exception();

        // 用以支持 co_return
        void return_void();

        // 用以支持 co_yield
        std::experimental::suspend_always yield_value(test_custom_coroutine_data*&);
    };

    // 下面的接入用侵入式的方式支持 co_await test_rpc_generator
    // MSVC 目前支持使用非侵入式的方式实现，但是clang不支持
    bool await_ready() noexcept;

    void await_resume();

    void await_suspend(std::experimental::coroutine_handle<promise_type>);

    int resume();
    void set_sum_times(int);
    bool is_done() const;
    test_custom_coroutine_data* data();
private:
    test_custom_coroutine(test_custom_coroutine_data*);
    test_custom_coroutine_data* data_;
    char fake_cache_miss_[64 - sizeof(test_custom_coroutine_data*)];
};

struct test_custom_coroutine_data {
    int sum_times;
    int yield_times;

    std::experimental::coroutine_handle<test_custom_coroutine::promise_type> handle;
};

test_custom_coroutine::promise_type::promise_type() {
    refer_data = std::make_unique<test_custom_coroutine_data>();
    refer_data->sum_times = 0;
    refer_data->yield_times = 0;
}
test_custom_coroutine test_custom_coroutine::promise_type::get_return_object_on_allocation_failure() {
    return test_custom_coroutine{ nullptr };
}

test_custom_coroutine test_custom_coroutine::promise_type::get_return_object() {
    return test_custom_coroutine{ refer_data.get() };
}

std::experimental::suspend_always test_custom_coroutine::promise_type::initial_suspend() {
    refer_data->handle = std::experimental::coroutine_handle<promise_type>::from_promise(*this);
    return std::experimental::suspend_always{}; // STL提供了一些自带的awaiter实现，我们其实很多情况下也不需要另外写，直接用STL就好了
}

std::experimental::suspend_always test_custom_coroutine::promise_type::final_suspend() {
    return std::experimental::suspend_always{}; // 和上面一样，也是STL自带的awaiter实现
}

void test_custom_coroutine::promise_type::unhandled_exception() {
    std::terminate();
}

// 用以支持 co_return
void test_custom_coroutine::promise_type::return_void() {
    refer_data->handle = nullptr;
}

// 用以支持 co_yield
std::experimental::suspend_always test_custom_coroutine::promise_type::yield_value(test_custom_coroutine_data*& coro_data) {
    // 每次调用都会执行,创建handle用以后面恢复数据
    if (nullptr != refer_data) {
        refer_data->handle = std::experimental::coroutine_handle<promise_type>::from_promise(*this);
        ++refer_data->yield_times;
    }

    coro_data = refer_data.get();
    return std::experimental::suspend_always{};
}

// 下面的接入用侵入式的方式支持 co_await test_custom_coroutine , 实际上benchmark过程中并没有用到
// MSVC 目前支持使用非侵入式的方式实现，但是clang不支持
bool test_custom_coroutine::await_ready() noexcept {
    // 准备好地标志是协程handle执行完毕了
    return !data_ || !data_->handle || data_->handle.done();
}

void test_custom_coroutine::await_resume() {
    // do nothing when benchmark
}

void test_custom_coroutine::await_suspend(std::experimental::coroutine_handle<promise_type>) {
    // do nothing when benchmark
    // 被外部模块 co_await , 这里完整的协程任务链流程应该是要把coroutine_handle记录到test_custom_coroutine
    // 在return_void后需要对这些coroutine_handle做resume操作，但是这里为了减少benchmark的额外开销和保持干净
    // 所以留空
}

int test_custom_coroutine::resume() {
    if (!await_ready()) {
        data_->handle.resume();
        return 1;
    }

    return 0;
}

void test_custom_coroutine::set_sum_times(int times) {
    if (data_) {
        data_->sum_times = times;
    }
}

bool test_custom_coroutine::is_done() const {
    return !(data_ && data_->handle);
}

test_custom_coroutine_data* test_custom_coroutine::data() {
    return data_;
}

test_custom_coroutine::test_custom_coroutine(test_custom_coroutine_data* d) : data_(d) {}

// 异步协程函数
test_custom_coroutine coroutine_start_main(test_custom_coroutine_data*& coro_data) {
    // create done

    // begin to yield
    while (coro_data != nullptr && coro_data->yield_times < coro_data->sum_times) {
        co_yield coro_data;
    }

    // finish all yield
    co_return;
}

// 这里模拟生成数据
bool coroutine_resume(std::vector<test_custom_coroutine>& in, long long& real_switch_times) {
    bool ret = false;
    for (auto& co : in) {
        real_switch_times += co.resume();
        if (!co.is_done()) {
            ret = true;
        }
    }

    return ret;
}

int main(int argc, char* argv[]) {
#ifdef __cpp_coroutines
    std::cout << "__cpp_coroutines: " << __cpp_coroutines << std::endl;
#endif
    puts("###################### C++20 coroutine ###################");
    printf("########## Cmd:");
    for (int i = 0; i < argc; ++i) {
        printf(" %s", argv[i]);
    }
    puts("");

    int switch_count = 100;
    int max_coroutine_number = 100000; // 协程数量

    if (argc > 1) {
        max_coroutine_number = atoi(argv[1]);
    }

    if (argc > 2) {
        switch_count = atoi(argv[2]);
    }

    std::vector<test_custom_coroutine> co_arr;
    std::vector<test_custom_coroutine_data*> co_data_arr;
    co_arr.reserve(static_cast<size_t>(max_coroutine_number));
    co_data_arr.resize(static_cast<size_t>(max_coroutine_number), nullptr);

    time_t       begin_time = time(NULL);
    CALC_CLOCK_T begin_clock = CALC_CLOCK_NOW();

    // create coroutines
    for (int i = 0; i < max_coroutine_number; ++i) {
        co_arr.emplace_back(coroutine_start_main(co_data_arr[i]));
        co_arr.back().set_sum_times(switch_count);
        co_data_arr[i] = co_arr.back().data();
    }

    time_t       end_time = time(NULL);
    CALC_CLOCK_T end_clock = CALC_CLOCK_NOW();
    printf("create %d coroutine, cost time: %d s, clock time: %d ms, avg: %lld ns\n", max_coroutine_number,
        static_cast<int>(end_time - begin_time), CALC_MS_CLOCK(end_clock - begin_clock),
        CALC_NS_AVG_CLOCK(end_clock - begin_clock, max_coroutine_number));

    begin_time = end_time;
    begin_clock = end_clock;

    // yield & resume from runner
    long long real_switch_times = static_cast<long long>(0);

    bool is_continue = true;
    while (is_continue) {
        is_continue = coroutine_resume(co_arr, real_switch_times);
    }
    // sub create - resume
    real_switch_times -= max_coroutine_number;

    end_time = time(NULL);
    end_clock = CALC_CLOCK_NOW();
    printf("switch %d coroutine contest %lld times, cost time: %d s, clock time: %d ms, avg: %lld ns\n", max_coroutine_number,
        real_switch_times, static_cast<int>(end_time - begin_time), CALC_MS_CLOCK(end_clock - begin_clock),
        CALC_NS_AVG_CLOCK(end_clock - begin_clock, real_switch_times));

    begin_time = end_time;
    begin_clock = end_clock;

    co_arr.clear();

    end_time = time(NULL);
    end_clock = CALC_CLOCK_NOW();
    printf("remove %d coroutine, cost time: %d s, clock time: %d ms, avg: %lld ns\n", max_coroutine_number,
        static_cast<int>(end_time - begin_time), CALC_MS_CLOCK(end_clock - begin_clock),
        CALC_NS_AVG_CLOCK(end_clock - begin_clock, max_coroutine_number));

    return 0;
}

```

其他库的测试代码在 https://gist.github.com/owt5008137/1842b56ac1edd5a7db54590d41af1c44

测试结果及对比
------------------------------------------------

| 组件(Avg)                   | 协程数：1 切换开销 | 协程数：1000 创建开销 | 协程数：1000 切换开销 | 协程数：30000 创建开销 | 协程数：30000 切换开销 |
|-----------------------------|--------------------|-----------------------|-----------------------|------------------------|------------------------|
| C++20 Coroutine - Clang     |  5 ns              | 130 ns                |   6 ns                | 136 ns                 |   9 ns                 |
| C++20 Coroutine - MSVC      | 10 ns              | 407 ns                |  14 ns                | 369 ns                 |  28 ns                 |

C++20 裸测试的性能真是非常夸张地高，基本上性能已经赶上 [call_in_stack][16] 这种对分支预测做优化的版本，并且还有不错的灵活性。这里性能测试的结果很好看一方面是 ```coroutine_handle<T>``` 的成员是个指针，再里面的管理上下文的部分我没法控制它的实现，所以没法模拟cache miss。另一方面也是由于它是使用operator new并且分析调用的函数需要多少栈来分配栈空间的，这样不会有内存缺页的问题（因为和其他的逻辑共享内存块），而且地址空间使用量也很小并且是按需分配的，也减少了系统调用的次数。还有一点影响比较大的是这次测试的C++20 Coroutine的代码全部是非线程安全的。而 [libcopp][1] 在实际应用中是搭配上了线程安全检查和一些防止误用的状态检查的，全是atomic操作，甚至 [libgo][5] 那种加锁的线程安全的检查，性能会会受到一定影响。如果在实际应用C++20 Coroutine的时候也加上这些检查，估计性能会下降几倍，但是应该还是会比现在的成熟方案要快一些。

不过现阶段 [《C++20 Coroutine》][5] 使用上还有些限制，所有使用 ```co_await``` 或者 ```co_yield``` 的函数返回值必须有 promise_type 。 也就是说如果嵌套使用或者递归调用的话不能直接用上层的协程对象，一旦出现嵌套使用只能 ```co_await``` 然后新创建一个协程对象。比如调用链 ```func1()->func2()->func3()->func4()``` ， 如果 func1 和 func4 是需要使用协程调用，要么得 func2 和 func3 也实现成协程，然后 func1 里 ```co_await func2()``` , 要么 func2 和 func3 把 func4 产生的 ```awaitable``` 对象透传回来，然后由 func1 来 ```co_await func2().awaitable``` 。 也就是说 func2 和 func3 对 func4 不能完全透明。这是 [《C++20 Coroutine》][5] 比不上 [libcopp][1] 的地方。 这也是我前段时间思考给 [libcopp][1] 接入 [《C++20 Coroutine》][5] 做Context管理的最大困难。

我们拿之前 [《协程框架(libcopp)v2优化、自适应栈池和同类库的Benchmark对比》][6] 对比过的其他库放一起来看：

| 组件(Avg)                           | 协程数：1 切换开销 | 协程数：1000 创建开销 | 协程数：1000 切换开销 | 协程数：30000 创建开销 | 协程数：30000 切换开销 |
|-------------------------------------|--------------------|-----------------------|-----------------------|------------------------|------------------------|
| 栈大小（如果可指定）                | 16 KB              |    2 MB               |    2 MB               |  64 KB                 |   64 KB                |
| C++20 Coroutine - Clang             |  5 ns              |  130 ns               |    6 ns               | 136 ns                 |    9 ns                |
| C++20 Coroutine - MSVC              | 10 ns              |  407 ns               |   14 ns               | 369 ns                 |   28 ns                |
| [libcopp][1]                        | 34 ns              |  4.1 us               |   80 ns               | 3.8 us                 |  223 ns                |
| [libcopp+动态栈池][1]               | 32 ns              |   96 ns               |   77 ns               | 212 ns                 |  213 ns                |
| [libcopp+libcotask][1]              | 50 ns              |  4.1 us               |  141 ns               | 4.2 us                 |  389 ns                |
| [libcopp+libcotask+动态栈池][1]     | 49 ns              |  134 ns               |  134 ns               | 256 ns                 |  371 ns                |
| [libco][6]+静态栈池                 | 84 ns              |  3.9 us               |  168 ns               | 4.2 us                 |  450 ns                |
| [libco][6]（共享栈4K占用）          | 83 ns              |  3.9 us               |  529 ns               | 3.9 us                 | 1073 ns                |
| [libco][6]（共享栈8K占用）          | 86 ns              |  4.0 us               |  828 ns               | 3.9 us                 | 1596 ns                |
| [libco][6]（共享栈32K占用）         | \-                 |  4.0 us               | 9152 ns               | 3.9 us                 | 11.5 us                |
| [libgo][5] 2019年9月master分支      |  53 ns             |  8.3 us               |  120 us               | 5.5 us                 |  237 ns                |
| [libgo][5] 2018年版本 with boost    | 197 ns             | 5.3 us                |  124 ns               | 2.3 us                 |  441 ns                |
| [libgo][5] 2018年版本 with ucontext | 539 ns             | 7.0 us                |  482 ns               | 2.7 us                 |  921 ns                |
| [goroutine(golang)][7]              | 425 ns             |  1.0 us               |  710 ns               | 1.0 us                 | 1047 ns                |
| linux ucontext                      | 439 ns             |  4.4 us               |  505 ns               | 4.8 us                 |  890 ns                |

> **关于[libgo][5]**： [libgo][5] 似乎比我最早测试的版本来了一次大改版，现在它也和[libcopp][1]一样内置了boost.context了，不再能自己切ucontext；另外它的执行线程Processer采用一次性从调度器分配一堆Task的方式去调度任务。这使得它的协程任务调度过程中不再需要保证线程安全了，少了很多同步操作和状态检查的开销。它可以这么设计的其中一个原因也是它是把协程任务的接口给隐藏起来的，用户不太会去显式调用它，也就不会有误用的问题。另外它的Task对象和以前的[libcopp][1] v1版一样是另外存储的，简单压测的话和[libcopp][1] v1版一样，缓存命中率会偏高，是更加无法真实地反映实际项目中的使用的。所以简单压测协程切换它的性能逼近 boost.context 原生cache 不miss时的开销（boost.context 原生切换 cache的miss的时候也到不了30ns，印象中以前测过是60ns+）。也是这个原因，它的协程数量上来以后命中率下降之后它的性能也下降得也非常厉害。我也尝试了下稍微改动了 [libgo][5] 的代码，提高cache miss的情况下，测试数据下降也很明显，不过 [libgo][5] 的切换性能仍然是和 [libcopp][1] 相近，不过我没太深入去看它的细节，不知道为什么增大栈的情况下它的切换性能和创建性能变化很剧烈，按道理只是分配了地址空间，并没有使用到不应该有这么大的变化。另外 [libgo][5] 的 ```co::CoroutineOptions``` 可以自定义全局的分配器，所以它也是可以自己手动接栈池的，否则它每次创建协程都会走mmap系统调用然后触发缺页中断，创建开销比较大。
> 按照 [libgo][5] 作者自己的测试来看， 关于[libgo][5]的性能大约是 [goroutine(golang)][7] 的3-4倍，这个数值可我之前测试的老版本的测试方法结果比较相近，也和 [libcopp][1] 的性能接近。所以也贴了以前的测试结果（以前跑测试的老机器和现在测试的新机器硬件有差异，老机器的单核切换性能普片比新机器高一些）。

最后
------------------------------------------------

欢迎有兴趣的小伙伴们一起交流哈。

[1]: https://github.com/owt5008137/libcopp
[2]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0973r0.pdf
[3]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4736.pdf
[4]: https://github.com/ultramanhu
[5]: https://owent.net/2019/1904.html
[6]: https://owent.net/2018/1806.html
[7]: https://en.cppreference.com/w/cpp/language/coroutines
[8]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0912r5.html
[9]: https://en.cppreference.com/w/cpp/language/coroutines
[10]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4775.pdf
[11]: https://golang.org/
[12]: https://golang.org/dl/#go1.13.1
[13]: https://www.boost.org/
[14]: https://www.boost.org/users/history/version_1_71_0.html
[15]: https://github.com/yyzybb537/libgo
[16]: https://github.com/yuanzhubi/call_in_stack
