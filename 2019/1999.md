---
author: owent
categories:
  - Article
  - Blablabla
date: 2019-08-29 20:08:58
draft: true
id: 1999
tags: 
tags: 
  - PALM
  - B+
  - tree
  - Latch-free
  - Parallel 
  - Many-Core
  - Multi-Core
  - BSP
title: PALM Tree - 适合多核并发架构的B+树 - 论文阅读小记
type: post
---

前言
------------------------------------------------

年初的时候再知乎上看到有人分享 [PLAM][1] 树的文章，看简介是专为多核并发而设计的树形结构。比较好奇所以抽时间来看了看它的设计原理和是如合做到高并发的。

首先按照论文里介绍的[PLAM][1]的特性：

+ Latch-free 的B+树批处理.\(个人理解差不多是无自旋锁\)
+ 多核友好 — 高扩展性，针对SIMD，对缓存友好
+ 高性能
  > (CPU: Intel Xeon X5680 * 2(6核12线程))
  > 128M数据存量时可达，40M次更新/秒。（平均每物理核心 3.33M，逻辑核1.67M的QPS）
  > 512K数据存量时可达，128M次更新/秒（平均每物理核心 10.67M，逻辑核5.33M的QPS）
  > 1.6倍于更新性能的查询性能
+ 极短的响应延迟，几乎和吞吐保持一致, 一般在60–350μs之间
+ 2.3X–19X the state of the art on [skewed distributions][3].
+ 将来的Intel Knights Ferry CPU可以获得1.5–2.1倍的性能。
+ 更容易测试和维护
+ 基于 [Bulk Synchronous Parallel (BSP) ][7] 模型。

简单的理解，PALM就是普通B+树然后在某些阶段执行同步操作，收敛工作线程来解决并发执行时传统方案的频繁加锁的问题。

PALM 批处理
------------------------------------------------

假设有数据库 \\\(D\\\) , 然后里面有全量的Key索引 \\\(K\\\) ， 然后索引对 \\\((k,r^∗_k)\\\) 。 \\\(r^∗_k\\\) 是指向实际数据集\\\(r_k\\\) 。
然后对于数据库 \\\(D\\\) 的树形结构索引 \\\(T_D\\\) [**PALM树**][1] 支持三种操作:

+ RETRIEVE(\\\(T_D\\\) , \\\(k\\\)): 返回 \\\(r_k\\\) 或 \\\(\Theta , if(k \notin T_D)\\\)
+ INSERT(\\\(T_D\\\) , \\\((k,e)\\\)): \\\(if(k \in T_D)\\\) ，追加数据 \\\(e\\\) 到 \\\(r_k\\\) ；否则初始化 \\\(r_k\\\) 为 \\\({e}\\\) ，然后增加新的指针对 \\\(r^∗_k\\\) 到 \\\(T_D\\\)
+ DELETE(\\\(T_D\\\) , \\\((k,e)\\\)): \\\(if(k \in T_D)\\\) ，把 \\\(e\\\) 从 \\\(r_k\\\) 里移除， 然后 \\\(if(length(r_k)=0)\\\) ，从 \\\(T_D\\\) 里移除指针对 \\\(r^∗_k\\\) ， \\\(if( k \notin T_D)\\\) ，忽略操作

PALM树的核心从系统层面来看最重要的就是它的批处理流程：

```
PALM(O, T[D], i, t)
  // O are queries, T[D] is the tree 
  // i is the thread-id, and t is the number of threads
  O[i] = PARTITION-INPUT (O, i, t)
  L[i] = SEARCH (O[i], T[D])
  SYNC(i, t)
  L'[i] = REDISTRIBUTE-WORK (L[0], . . . , L[t-1], i)
  (R[i], O'[L'[i]]) = RESOLVE-HAZARDS(L'[i] , O, D)
  for (O[λ], λ) in (O'[L'[i]], L'[i])
    M[1][i] = M[1][i] ∪ MODIFY-NODE (O[λ], λ)
  SYNC(i, t)
  for d = 1 to depth (T[D]) - 1
    M[d'][i] = REDISTRIBUTE-WORK(M[d][0], ..., M[d][t-1], i)
    for (Λ, η) in M[d'][i]
      M[d+1][i] = M[d+1][i] ∪ MODIFY-NODE (Λ, η)
    SYNC(i, t)
  if (i == 0)
    HANDLE-ROOT(⋃(M[d+1][i]), T[D])
  return (R[0], ..., R[t-1])
```

> 上面公式里由于Markdown和公式渲染的限制改成了偏程序的表达形式:
> ```O``` 是请求集合， ```T[D]``` 是Palm树结构, ```i``` 是线程ID、 ```t``` 是总线程数。


B树+每次节点操作前同步actor线程

### REDISTRIBUTE-WORK

上面流程里的 ```REDISTRIBUTE-WORK``` 这一步，简明来说就是构造一个新的执行节点的集合 \\\(L'_i\\\)  ，让它和原来的执行节点的集合 \\\(L_i\\\) 和 \\\(L_j\\\) 满足下面的关系。（ ```i``` 和 ```j``` 是线程ID）

$$
L'_i = {λ \in L_i|λ \notin L_j , \forall 0 \le j < i}
$$

上面这个公式的作用是决定一个节点的执行者应该由哪个线程执行。其实换一种程序化的描述很简单，就是把所有的同时有多个执行线程的节点的归属权交给ID小的那个。

> 原Paper里非得写个公式化的东西并且和程序化思维反着来，理解起来绕了一圈。

### RESOLVE-HAZARDS

节点内处理 MODIFY-NODE
------------------------------------------------

```
MODIFY-NODE (Λ, η)
  // Λ is sequence of modifications to node η.
  // If η is internal, Λ is a modification list.
  // If η is a leaf, Λ is a series of INSERT and DELETE queries.
  E = items (η)
  K = ∅
  for m in Λ
    K = K ∪ orphaned-keys (m)
    if class (m) == "+"
      E = E ∪ items (m)
    elseif class (m) == "−"
      E = E \ items (m)
  if |E| > MAX-DEGREE
    (η, η', η'', ...) = BIG-SPLIT(E)
    return {"+", parent (η) , η', η'', ..., K}
  elseif |E| < MIN-DEGREE
    return {"−", parent (η) , η, K ∪ descendant-keys (E)}
  else
    child-ranges (η) = E
    return {∅, K}
```

其他细节优化
------------------------------------------------

请求排序和线程间同步优化
[缓存预取指令][5]和[数据预取][4]
使用SIMD指令集

最后
------------------------------------------------

度这篇Paper主要是了解一下它的原理，可能对以后默写系统的设计实现有参考价值。我就没有去写一个了，Paper里的性能测试报告差不多是个量级层面的参考，我就不贴了。他们的测试机器配置还不错，比我们目前项目里用的好一些，性能差别也不会大到哪里去。

文中如果有哪些地方理解有偏差欢迎小伙伴们交流指正哈。

[1]: http://www.vldb.org/pvldb/vol4/p795-sewall.pdf "PALM: Parallel Architecture-Friendly Latch-FreeModifications to B+ Trees on Many-Core Processors"
[2]: https://en.wikipedia.org/wiki/Knights_Ferry_(Intel) "Knights Ferry"
[3]: https://www.sciencedirect.com/topics/mathematics/skewed-distributions "skewed distributions"
[4]: https://en.wikipedia.org/wiki/Cache_prefetching "Cache prefetching"
[5]: https://en.wikipedia.org/wiki/Cache_control_instruction "Cache control instruction"
[6]: https://gcc.gnu.org/projects/prefetch.html "GCC - Data Prefetch Support"
[7]: https://en.wikipedia.org/wiki/Bulk_synchronous_parallel
